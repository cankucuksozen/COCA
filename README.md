Official GitHub repository for **CVPR2025 accepted paper**: 
# Hierarchical Compact Clustering Attention (COCA) for Unsupervised Object-Centric Learning

[![arXiv](https://img.shields.io/badge/arXiv-2505.02071-b31b1b.svg)](https://arxiv.org/abs/2505.02071)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## 🔗 Links
- [📄 Paper (arXiv)](https://arxiv.org/abs/2505.02071)
- [📄 Camera-ready PDF](paper.pdf)
- [🌐 Project Page](https://cankucuksozen.github.io/COCA)
- [🧠 BibTeX](bibtex.bib)

---

## 🧠 Abstract
We propose the **Compact Clustering Attention (COCA)** layer, an effective *building block* that introduces a *hierarchical strategy* for **object-centric representation learning**, while solving the unsupervised object discovery task on single images. COCA is an *attention-based clustering module* capable of extracting object-centric representations from multi-object scenes, when cascaded into a *bottom-up hierarchical network architecture*, referred to as COCA-Net. At its core, COCA utilizes a *novel clustering algorithm* that leverages the **physical concept of compactness, to highlight distinct object centroids in a scene, providing a spatial inductive bias**. Thanks to this strategy, COCA-Net generates high-quality segmentation masks on both the decoder side and, notably, the encoder side of its pipeline. Additionally, COCA-Net is not bound by a predetermined number of object masks that it generates and handles the segmentation of background elements better than its competitors. We demonstrate COCA-Net’s segmentation performance on six widely adopted datasets, achieving superior or competitive results against the state-of-the-art models across nine different evaluation metrics.

---

## 🛠️ Installation
Coming soon.

---

## 📜 License
- Code: [MIT License](LICENSE)
- Website text/images: [CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/)
