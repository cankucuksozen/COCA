<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>COCA: Compact Clustering Attention – CVPR 2025</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body { font-family: sans-serif; max-width: 800px; margin: 40px auto; padding: 0 20px; }
    h1, h2 { margin-bottom: 0; }
    h2 { font-weight: normal; font-size: 1.3em; }
    a { color: #007acc; text-decoration: none; }
    a:hover { text-decoration: underline; }
    img { max-width: 100%; margin-top: 20px; }
    .authors { font-size: 1em; color: #333; margin: 10px 0 20px; }
    .section { margin-top: 40px; }
    .bibtex { background: #f5f5f5; padding: 10px; font-family: monospace; font-size: 0.9em; }
    footer { margin-top: 60px; font-size: 0.9em; color: #666; text-align: center; }
  </style>
</head>
<body>

<h1>Hierarchical Compact Clustering Attention (COCA) for Unsupervised Object-Centric Learning</h1>

<div class="authors">
  Can Küçüksözen<sup>1,2</sup>, Yücel Yemez<sup>1,2</sup><br>
  <sup>1</sup>Koç University, <sup>2</sup>KUIS AI Center<br>
  <a href="mailto:ckucuksozen19@ku.edu.tr">ckucuksozen19@ku.edu.tr</a>, 
  <a href="mailto:yyemez@ku.edu.tr">yyemez@ku.edu.tr</a>
</div>

<div style="display: flex; gap: 20px; align-items: center; justify-content: center; margin-top: 20px;">
  <img src="assets/KocUni_logo.png" alt="Koç University" height="50">
  <img src="assets/KUIS_logo.png" alt="KUIS AI Center" height="50">
  <img src="assets/CVPR_Nashville_Final Logo.png" alt="CVPR 2025" height="50">
</div>

<p>
  <a href="https://arxiv.org/abs/2505.02071">[Paper]</a>
  <a href="assets/paper.pdf">[PDF]</a>
  <a href="https://github.com/cankucuksozen/COCA">[Code]</a>
  <a href="#bibtex">[BibTeX]</a>
</p>

<div class="section">
  <h2>Teaser Figure</h2>
  <p>
    Figure 1. Compactness scores obtained for each pixel in the scene, across four different datasets. The transition from bright yellow to deep purple signifies decreasing compactness. To obtain these scores, a trained COCA-Net encoder is used to generate object masks. Each object mask is then broadcasted to pixels based on the pixel-object assignments. This operation associates every pixel with a copy of its object’s mask. Finally, compactness scores for each pixel’s mask are calculated via Eq. 3 of the paper.  </p>
  <img src="assets/four_datasets_compactness.png" alt="COCA teaser image">
</div>

<div class="section">
  <h2>Abstract</h2>
  <p>
    We propose the Compact Clustering Attention (COCA) layer, an effective building block that introduces a hierarchical strategy for object-centric representation learning, while solving the unsupervised object discovery task on single images. COCA is an attention-based clustering module capable of extracting object-centric representations from multi-object scenes, when cascaded into a bottom-up hierarchical network architecture, referred to as COCA-Net. At its core, COCA utilizes a novel clustering algorithm that leverages the physical concept of compactness, to highlight distinct object centroids in a scene, providing a spatial inductive bias. Thanks to this strategy, COCA-Net generates high-quality segmentation masks on both the decoder side and, notably, the encoder side of its pipeline. Additionally, COCA-Net is not bound by a predetermined number of object masks that it generates and handles the segmentation of background elements better than its competitors. We demonstrate COCA-Net’s segmentation performance on six widely adopted datasets, achieving superior or competitive results against the state-of-the-art models across nine different evaluation metrics.
  </p>
</div

<div class="section">
  <h2 id="bibtex">BibTeX</h2>
  <div class="bibtex">
@InProceedings{Kucuksozen_2025_CVPR,<br>
&nbsp;&nbsp;author = {Kucuksozen, Can and Yemez, Yucel},<br>
&nbsp;&nbsp;title = {Hierarchical Compact Clustering Attention (COCA) for Unsupervised Object-Centric Learning},<br>
&nbsp;&nbsp;booktitle = {Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR)},<br>
&nbsp;&nbsp;month = {June}<br>
&nbsp;&nbsp;year = {2025}<br>
&nbsp;&nbsp;pages = {25388-25398}<br>
    }
  </div>
</div>

<footer>
  © 2025 Can Küçüksozen | Site adapted from Jon Barron’s template.  
</footer>

</body>
</html>
